{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klhlYsp4I9ea"
      },
      "outputs": [],
      "source": [
        "# Updated GAN CODE\n",
        "# Data pre-processing pipeline + GAN for the KITTI Dataset.\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import torch.nn.init\n",
        "import os\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1V0ck36JbXX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(r'/content/drive/', force_remount = True) # mounting the drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeVxsBoHJejr"
      },
      "outputs": [],
      "source": [
        "basePath = r'/media/athrva/New Volume/cis520/Final Project/Processed_Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b74ppLhUJhsY"
      },
      "outputs": [],
      "source": [
        "# Some Custom Transformations (adapted code)\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "'''Set of tranform random routines that takes list of inputs as arguments,\n",
        "in order to have random but coherent transformations.'''\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for t in self.transforms:\n",
        "            images = t(images)\n",
        "        return images\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, images):\n",
        "        for tensor in images:\n",
        "            for t, m, s in zip(tensor, self.mean, self.std):\n",
        "                t.sub_(m).div_(s)\n",
        "        return images\n",
        "\n",
        "\n",
        "class ArrayToTensor(object):\n",
        "    def __call__(self, images):\n",
        "        tensors = []\n",
        "        for im in images:\n",
        "            # put it from HWC to CHW format\n",
        "            im = np.transpose(im, (2, 0, 1))\n",
        "            tensors.append(torch.from_numpy(im).float()/255)\n",
        "        return tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "903UYVtMJl7F"
      },
      "outputs": [],
      "source": [
        "### Dataloaders using pytorch frameworks\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "def depthByName(path):\n",
        "    num = path.split('.jpg')[0].split(os.path.sep)[-1]\n",
        "    return num\n",
        "\n",
        "def imageByName(path):\n",
        "    num = path.split('.jpg')[0].split(os.path.sep)[-1] \n",
        "    return num\n",
        "\n",
        "def sortPaths(imgPaths, dmapPaths):\n",
        "    imgPaths = sorted(imgPaths, key = imageByName);\n",
        "    dmapPaths = sorted(dmapPaths, key = depthByName);\n",
        "    return imgPaths, dmapPaths\n",
        "\n",
        "\n",
        "def validityCheckPairs(img_dmap_pairs): # checks the validity of the incoming data (checks whether data is pairwise)\n",
        "    counter = 0\n",
        "\n",
        "    for pair in img_dmap_pairs:\n",
        "      img_name = pair[0].split('/')[-1].split('.')[0].split('_')\n",
        "      dmap_name = pair[1].split('/')[-1].split('.')[0].split('_')\n",
        "\n",
        "      img_ID = img_name[1] + img_name[3]\n",
        "      dmap_ID = dmap_name[1] + dmap_name[3]\n",
        "      \n",
        "      assert(img_ID == dmap_ID)\n",
        "\n",
        "      counter += 1\n",
        "\n",
        "    print(f'Test Passed : All data is pairwise. Number of Samples tested : {counter}')\n",
        "    print('===================================')\n",
        "\n",
        "\n",
        "def buildPairs(dmaps, imgs):\n",
        "    pairs = []\n",
        "    for i in imgs:\n",
        "        img_name = i.split('/')[-1].split('.')[0].split('_')\n",
        "        dmap_path = basePath + '/dmaps/' + img_name[0] + '_' + img_name[1] + \\\n",
        "                            '_' + 'dmap' + '_' + img_name[3] + '.jpg'\n",
        "        \n",
        "        if dmap_path in dmaps:\n",
        "            pairs.append([i, dmap_path])\n",
        "    return pairs\n",
        "\n",
        "def getDataPaths(): # Gets the paths were data is stored.\n",
        "    Directories = glob(basePath + os.path.sep + '*')\n",
        "\n",
        "    imgPathsDir = glob(Directories[0] + os.path.sep + '*.jpg');\n",
        "    dmapPathsDir = glob(Directories[1] + os.path.sep + '*.jpg');\n",
        "    imgPathsDir, dmapPathsDir = sortPaths(imgPathsDir, dmapPathsDir);\n",
        "    \n",
        "    # Figure out which of the two has fewer entries\n",
        "    # bottleneck = np.argmin([len(imgPathsDir), len(dmapPathsDir)])\n",
        "    # For now, we know that images has fewer entries than dmaps\n",
        "    img_dmap_pairs = buildPairs(imgPathsDir, dmapPathsDir)\n",
        "\n",
        "    validityCheckPairs(img_dmap_pairs)\n",
        "    # Check again to be sure\n",
        "    validityCheckPairs(img_dmap_pairs)\n",
        "\n",
        "    return img_dmap_pairs\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return gray\n",
        "\n",
        "## Image Dataloader\n",
        "class ImageDataset(Dataset):\n",
        "   \n",
        "    def __init__(self,\n",
        "                 paths,\n",
        "                 op,\n",
        "                 transforms=None):\n",
        "        \"\"\"      \n",
        "        Args:\n",
        "            op (str): \"train\", \"val\", or \"test\" to indicate the split type\n",
        "            transforms (list or None): Image transformations to apply upon loading.\n",
        "        \"\"\"\n",
        "        self.paths = paths\n",
        "        self.transform = transforms\n",
        "        self.op = op\n",
        "\n",
        "        self.num_ex = len(paths)\n",
        "\n",
        "        try:\n",
        "            if self.op == 'train':\n",
        "                self.split_paths = self.paths[0:int(0.6*self.num_ex)]\n",
        "            elif self.op == 'val':\n",
        "                self.split_paths = self.paths[int(0.6*self.num_ex):int(0.8*self.num_ex)]\n",
        "            elif self.op == 'test':\n",
        "                self.split_paths = self.paths[int(0.8*self.num_ex):int(self.num_ex)]\n",
        "\n",
        "        except ValueError:\n",
        "            print('op is not train, val, or test')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.split_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        dmap = io.imread(self.split_paths[idx][1])\n",
        "        img = io.imread(self.split_paths[idx][0])\n",
        "\n",
        "        img = resize(img, (img.shape[0] // 2, img.shape[1] // 2),\n",
        "                       anti_aliasing=True)\n",
        "        dmap = resize(dmap, (dmap.shape[0] // 2, dmap.shape[1] // 2),\n",
        "                       anti_aliasing=True)\n",
        "        dmap = np.expand_dims(rgb2gray(dmap),0)\n",
        "        if self.transform:\n",
        "          img, dmap = self.img_transform(img, dmap)\n",
        "\n",
        "        sample = {'img': img, 'dmap': dmap}\n",
        "        return sample\n",
        "\n",
        "    def img_transform(self, img, dmap):\n",
        "        ## Apply Transformations\n",
        "        img = self.transform(img)\n",
        "        dmap = torch.from_numpy(dmap).type(torch.float32)\n",
        "        return img, dmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_IU8kF1JqAY"
      },
      "outputs": [],
      "source": [
        "data_paths = getDataPaths()\n",
        "img_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(data_paths, op=\"train\", transforms=img_transform)\n",
        "val_dataset = ImageDataset(data_paths, op=\"val\", transforms=img_transform)\n",
        "test_dataset = ImageDataset(data_paths, op=\"test\", transforms=img_transform)\n",
        "\n",
        "print(train_dataset.__len__())\n",
        "print(val_dataset.__len__())\n",
        "print(test_dataset.__len__())\n",
        "\n",
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "test_batch_size = 1\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False)\n",
        "validation_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "train_dataset_notensor = ImageDataset(data_paths, op=\"train\", transforms=None)\n",
        "train_dataloader_notensor = DataLoader(train_dataset_notensor, batch_size=train_batch_size, shuffle=False)\n",
        "\n",
        "# Load some image and view them\n",
        "for k,data in enumerate(train_dataloader_notensor):\n",
        "  plt.figure()\n",
        "  plt.imshow(data['img'][0])\n",
        "  plt.figure()\n",
        "  plt.imshow(data['dmap'][0][0])\n",
        "  plt.show()\n",
        "  if k >= 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TTxlhyDJuWQ"
      },
      "outputs": [],
      "source": [
        "### UNET FROM https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "### Model definitions.\n",
        "\n",
        "class pretrainedG():\n",
        "    def __init__(self,in_channels, out_channels, init_features):\n",
        "        self.in_channels = in_channels;\n",
        "        self.out_channels = out_channels;\n",
        "        self.init_features = init_features;\n",
        "    def get(self):\n",
        "        gM = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "            in_channels=self.in_channels, out_channels=self.out_channels,\n",
        "             init_features=self.init_features, pretrained=True)\n",
        "        return gM\n",
        "\n",
        "class Discriminator(nn.Module): # The PatchGAN discriminator\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalization:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.gM = nn.Sequential(\n",
        "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        img_input = torch.cat((img_A, img_B), 1)\n",
        "        return self.gM(img_input)\n",
        "\n",
        "class pretrainedD(): # Pretrained ResNet 18 as discriminator (Not Used)\n",
        "    def __init__(self, in_channels, out_channels, init_features):\n",
        "        self.in_channels = in_channels;\n",
        "        self.out_channels = out_channels;\n",
        "        self.init_features = init_features;\n",
        "    def get(self):\n",
        "        model = torch.hub.load('pytorch/vision', 'resnet18',pretrained=True)\n",
        "        return model\n",
        "patch = (1, 128 //16, 416 //16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUMghjGOJwrw"
      },
      "outputs": [],
      "source": [
        "print(*patch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Initialize Optimizer and Learning Rate Scheduler\n",
        "\n",
        "EPOCHS = 30\n",
        "VISUALIZE = True\n",
        "TRAIN = 1\n",
        "MODEL_SAVE_DIR = r'/media/athrva/New Volume/cis520/Final Project/TrainedGAN/'\n",
        "MODEL_SAVE_DIR_RUD = r'/media/athrva/New Volume/cis520/Final Project/GAN_MODELS/'\n",
        "TRAIN_LOG_DIR_RUD = r'/media/athrva/New Volume/cis520/Final Project/'\n",
        "TRAIN_LOG_DIR = r'/media/athrva/New Volume/cis520/Final Project/'\n",
        "\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 1\n",
        "\n",
        "\n",
        "loss_metric = torch.nn.MSELoss() # For regression task\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_boole = True\n",
        "else:\n",
        "    gpu_boole = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW5nKRfGKr97"
      },
      "outputs": [],
      "source": [
        "# get logger\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "trainLogger = open(TRAIN_LOG_DIR + 'train.log', 'a+') # Logger\n",
        "\n",
        "\n",
        "def sc1(tensor):\n",
        "    tensor = (tensor[0,0,:,:] + tensor[0,1,:,:] + tensor[0,2,:,:])/3.\n",
        "    \n",
        "    return tensor.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor # Generic definition of Tensor default type\n",
        "\n",
        "\n",
        "if TRAIN == 1:\n",
        "    print('Pre-trained Model Found...Reusing')\n",
        "    \n",
        "    gM = pretrainedG(in_channels=3, out_channels= 1, init_features= 32)\n",
        "    gM = gM.get()\n",
        "    dM = Discriminator(in_channels = 1)\n",
        "    if use_cuda:\n",
        "        gM.cuda()\n",
        "        dM.cuda()\n",
        "    device = torch.device('cuda')\n",
        "    if os.path.exists(MODEL_SAVE_DIR + '/SegNet.pt'):\n",
        "        checkpoint = torch.load(MODEL_SAVE_DIR + '/SegNet.pt', map_location=device)\n",
        "        gM.load_state_dict(checkpoint['model_state_dict'])\n",
        "        dM.load_state_dict(checkpoint['dis_state_dict'])\n",
        "        optimizer_G = torch.optim.Adam(gM.parameters(), lr=learning_rate)\n",
        "        optimizer_D = torch.optim.Adam(dM.parameters(), lr=learning_rate/2) # Half learning rate for the discriminator\n",
        "        optimizer_G.load_state_dict(checkpoint['G_optimizer_state_dict'])\n",
        "        optimizer_D.load_state_dict(checkpoint['D_optimizer_state_dict'])\n",
        "        schedulerG = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n",
        "        schedulerD = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\n",
        "        dM.train()\n",
        "        gM.train()\n",
        "    else:\n",
        "        if use_cuda:\n",
        "            gM.cuda()\n",
        "            dM.cuda()\n",
        "        optimizer_G = torch.optim.Adam(gM.parameters(), lr=learning_rate)\n",
        "        optimizer_D = torch.optim.Adam(dM.parameters(), lr=learning_rate/2)\n",
        "        schedulerG = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n",
        "        schedulerD = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\n",
        "        \n",
        "        dM.train()\n",
        "        gM.train()\n",
        "        \n",
        "\n",
        "    # similarity loss definition\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    criterion_GAN = torch.nn.L1Loss()\n",
        "\n",
        "    # continuity loss definition\n",
        "    loss_hpy = torch.nn.L1Loss(size_average = True)\n",
        "    loss_hpy_ = torch.nn.MSELoss()\n",
        "    \n",
        "    a = torch.Tensor([[1, 0, -1],\n",
        "    [2, 0, -2],\n",
        "    [1, 0, -1]]) # Kernel for gradient computation\n",
        "\n",
        "    a = a.view((1,1,3,3)).cuda()\n",
        "\n",
        "    b = torch.Tensor([[1, 2, 1],\n",
        "    [0, 0, 0],\n",
        "    [-1, -2, -1]]) # Kernel for gradient computation\n",
        "\n",
        "    b = b.view((1,1,3,3)).cuda()\n",
        "    \n",
        "\n",
        "    sig = torch.nn.Sigmoid()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "            \n",
        "            x = batch[\"img\"]\n",
        "            y = batch[\"dmap\"]\n",
        "            if gpu_boole:\n",
        "                x = x.cuda().float()\n",
        "                y = y.cuda().float()\n",
        "\n",
        "            epoch_loss = 0\n",
        "\n",
        "            real_A, real_B = x, y\n",
        "            real_B = real_B.cuda()\n",
        "            real_A = real_A.cuda()\n",
        "            real_B = real_B\n",
        "            \n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            fake_B = gM(real_A)\n",
        "            fake_B = sig(fake_B) # pass the model output through a sigmoid (optional)\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n",
        "            fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n",
        "\n",
        "            \n",
        "\n",
        "            pred_fake = dM(fake_B, sc1(real_A))\n",
        "\n",
        "            \"\"\"Code for the novel gradient loss\"\"\"\n",
        "            \n",
        "            G_x = F.conv2d(real_B, a)\n",
        "            G_y = F.conv2d(real_B, b)\n",
        "            F_x = F.conv2d(fake_B, a)\n",
        "            F_y = F.conv2d(fake_B, b)\n",
        "            G = sig((torch.pow(G_x,2)/torch.max(torch.pow(G_x,2)))+ (torch.pow(G_y,2)/torch.max(torch.pow(G_y,2))))\n",
        "            F_ = sig((torch.pow(F_x,2)/torch.max(torch.pow(F_x,2)))+ (torch.pow(F_y,2)/torch.max(torch.pow(F_y,2))))\n",
        "    \n",
        "\n",
        "            lhpy = loss_hpy(fake_B,real_B)\n",
        "            lhpy_ = loss_hpy_(fake_B,real_B)\n",
        "            \n",
        "            # Total loss : It has a few components\n",
        "            loss_G = 0.5*torch.sum(torch.abs(torch.abs(G) - torch.abs(F_))) + 1*(lhpy + lhpy_) + 0.5*loss_fn(pred_fake, valid) + 3*criterion_GAN(pred_fake, valid)\n",
        "            \n",
        "            loss_G.backward()\n",
        "            epoch_loss += loss_G.item()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            if batch_idx % 5 == 0: # Update the discriminator every 5 batches instead of 1.\n",
        "                optimizer_D.zero_grad()\n",
        "                #pass\n",
        "                # Real loss\n",
        "                pred_real = dM(real_B, sc1(real_A))\n",
        "                loss_real = criterion_GAN(pred_real,valid)\n",
        "\n",
        "                # Fake loss\n",
        "                pred_fake = dM(fake_B.detach(), sc1(real_A))\n",
        "                loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "                # Total loss\n",
        "                loss_D = (loss_real + loss_fake)\n",
        "                loss_D.backward()\n",
        "                optimizer_D.step()\n",
        "\n",
        "            trainLogger.write(f'{loss_G.item()}'+','+f'{loss_D.item()}'+'\\n')\n",
        "            with open(TRAIN_LOG_DIR_RUD + 'training_info.txt','a+') as file: # redundant logger\n",
        "                file.write(f'G Loss : {loss_G.item()}, D Loss : {loss_D.item()}')\n",
        "            \n",
        "            if VISUALIZE:\n",
        "                im_target = fake_B.detach().cpu().numpy()[0]\n",
        "                im_target = im_target/abs(im_target.max())\n",
        "                im_targetgt = real_B.detach().cpu().numpy()[0]\n",
        "                im_target_rgb = im_target\n",
        "                im_real = x[0].detach().cpu().numpy()\n",
        "                im_target_rgb = np.vstack([rgb2gray(np.moveaxis(im_real,0,-1)),im_targetgt[0],\n",
        "                                    im_target_rgb[0]])\n",
        "                cv2.imshow('Output : ', im_target_rgb)\n",
        "                cv2.waitKey(5)\n",
        "        \n",
        "        \n",
        "        print('Current Epoch Loss : ', epoch_loss)\n",
        "        \n",
        "        print (batch_idx, '/', EPOCHS, '|',' | loss G :', loss_G.item(), '|', '| loss D :', loss_D.item())\n",
        "        \n",
        "        torch.save({'model_state_dict' : gM.state_dict(),\n",
        "                        'G_optimizer_state_dict' : optimizer_G.state_dict(),\n",
        "                        'D_optimizer_state_dict' : optimizer_D.state_dict(),\n",
        "                        'dis_state_dict' : dM.state_dict()}, MODEL_SAVE_DIR_RUD + f'SegNet_17{epoch}.pt');\n",
        "        torch.save({'model_state_dict' : gM.state_dict(),\n",
        "                        'G_optimizer_state_dict' : optimizer_G.state_dict(),\n",
        "                        'D_optimizer_state_dict' : optimizer_D.state_dict(),\n",
        "                        'dis_state_dict' : dM.state_dict()}, MODEL_SAVE_DIR + 'SegNet.pt');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## PREDICTION PIPELINE.\n",
        "# This is a simple script to visualize the model's performance on the data images.\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "PREDICT = 1\n",
        "\n",
        "once = True\n",
        "\n",
        "def sc1(tensor):\n",
        "    tensor = (tensor[0,0,:,:] + tensor[0,1,:,:] + tensor[0,2,:,:])/3.\n",
        "    return tensor.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "\n",
        "if PREDICT == 1:\n",
        "    print('Pre-trained Model Found...Reusing')\n",
        "    \n",
        "    gM = pretrainedG(in_channels=3, out_channels= 1, init_features= 32)\n",
        "    gM = gM.get()\n",
        "    dM = Discriminator(in_channels = 1)\n",
        "    if use_cuda:\n",
        "        gM.cuda()\n",
        "        dM.cuda()\n",
        "    device = torch.device('cuda')\n",
        "    if os.path.exists(MODEL_SAVE_DIR + '/SegNet.pt'):\n",
        "        checkpoint = torch.load(MODEL_SAVE_DIR + '/SegNet.pt', map_location=device)\n",
        "        gM.load_state_dict(checkpoint['model_state_dict'])\n",
        "        dM.load_state_dict(checkpoint['dis_state_dict'])\n",
        "        optimizer_G = torch.optim.Adam(gM.parameters(), lr=learning_rate)\n",
        "        optimizer_D = torch.optim.Adam(dM.parameters(), lr=learning_rate/2)\n",
        "        optimizer_G.load_state_dict(checkpoint['G_optimizer_state_dict'])\n",
        "        optimizer_D.load_state_dict(checkpoint['D_optimizer_state_dict'])\n",
        "        schedulerG = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n",
        "        schedulerD = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\n",
        "        dM.train()\n",
        "        gM.train()\n",
        "    else:\n",
        "        print('No Model Found...')\n",
        "        dM.train()\n",
        "        gM.train()\n",
        "        \n",
        "\n",
        "    sig = torch.nn.Sigmoid()\n",
        "\n",
        "    for epoch in range(1):\n",
        "        for batch_idx, batch in enumerate(validation_dataloader): # could be test_dataloader.\n",
        "            \n",
        "           \n",
        "            x = batch[\"img\"]\n",
        "            y = batch[\"dmap\"]\n",
        "            if gpu_boole:\n",
        "                x = x.cuda().float()\n",
        "                y = y.cuda().float()\n",
        "                \n",
        "            epoch_loss = 0\n",
        "\n",
        "            real_A, real_B = x, y\n",
        "            real_B = real_B.cuda()\n",
        "            real_A = real_A.cuda()\n",
        "            real_B = real_B\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            fake_B = gM(real_A)\n",
        "            im_target = fake_B.detach().cpu().numpy()[0]\n",
        "            im_target = im_target/abs(im_target.max())\n",
        "            im_targetgt = real_B.detach().cpu().numpy()[0]\n",
        "            im_target_rgb = im_target\n",
        "            im_real = x[0].detach().cpu().numpy()\n",
        "            im_target_rgb = np.vstack([im_targetgt[0],\n",
        "                                im_target_rgb[0]])\n",
        "            if once == True:\n",
        "                plt.imsave(basePath + os.path.sep + 'output.png', im_target_rgb)\n",
        "                once = False\n",
        "            cv2.imshow('Output : ', im_target_rgb)\n",
        "            cv2.waitKey(5)\n",
        "            plt.imsave(f'/media/athrva/New Volume/cis520/Final Project/Progression/out_{batch_idx}.png', im_target_rgb)\n",
        "            \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
